{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下一跳预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需安装如下依赖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch\n",
    "# !pip install -q numpy\n",
    "# !pip install -q pandas\n",
    "# !pip install -q scikit-learn\n",
    "# !pip install -q tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有依赖\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机种子，设置device\n",
    "seed = 3407\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'mps'  # for Apple\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bi-LSTM 需要两个隐藏状态\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSequence(df, features, window_size):\n",
    "    # 找到轨迹长度 >= 15的所有轨迹\n",
    "    traj_index_list = df.groupby(['traj_id']).size()        # Series\n",
    "    traj_index_list = traj_index_list[traj_index_list > 15]\n",
    "\n",
    "    # 按照滑动窗口进行划分\n",
    "    seq = []\n",
    "    label = []\n",
    "    for index, _ in traj_index_list.items():\n",
    "        traj_id = index\n",
    "        trajectory = df[(df['traj_id'] == traj_id)][features].values.tolist()\n",
    "        num_splits = len(trajectory) - window_size + 1\n",
    "        for i in range(num_splits):\n",
    "            seq.append(trajectory[i:i + window_size - 1])\n",
    "            label.append(trajectory[i + window_size - 1])\n",
    "    seq = torch.tensor(np.array(seq), dtype=torch.float32).to(device)\n",
    "    label = torch.tensor(np.array(label), dtype=torch.float32).to(device)\n",
    "    return seq, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 训练 & 评估定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 RMSE（只计算点坐标和距离，不包括时间、速度等）\n",
    "def calc_rmse(predictions, targets):\n",
    "    mse = torch.mean((predictions[:, :3] - targets[:, :3]) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(train_X, train_Y, val_X, val_Y, model,\n",
    "               lr=1e-2, epoch_num=20, logging_steps=5):\n",
    "    # 使用 DataLoader 和 TensorDataset 批量加载数据\n",
    "    train_set = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True, generator=torch.Generator(device=device))\n",
    "    test_set = TensorDataset(val_X, val_Y)\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "    # 初始化损失函数和优化器\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # 模型训练\n",
    "    for epoch in tqdm(range(epoch_num)):\n",
    "        loss = 0.0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += loss.item()\n",
    "\n",
    "        # log\n",
    "        if epoch % logging_steps == (logging_steps - 1):\n",
    "            print(f\"Epoch {epoch + 1}, loss: {loss / len(train_loader):.6f}\")\n",
    "\n",
    "    # 用验证集评估\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs)\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    loss = criterion(preds, val_Y)\n",
    "    rmse = calc_rmse(preds, val_Y)\n",
    "\n",
    "    return model, loss.item(), rmse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv('data/traj.csv')[280000:360000]\n",
    "\n",
    "# 1. 将时间time转为基于最早时间的偏移time_offset\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "base_time = df['time'].min()\n",
    "df['time_offset'] = (df['time'] - base_time).dt.total_seconds()\n",
    "\n",
    "# 2. 将coordinates列转换为经度和纬度两列\n",
    "df[['longitude', 'latitude']] = pd.DataFrame(df['coordinates'].apply(lambda x: eval(x)).tolist(), index=df.index)\n",
    "\n",
    "# 3. 将holidays转为float32\n",
    "df['holidays'] = df['holidays'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部特征组合\n",
    "all_features = [\n",
    "    ['longitude', 'latitude', 'current_dis'],\n",
    "    ['longitude', 'latitude', 'current_dis', 'speeds'],\n",
    "    ['longitude', 'latitude', 'current_dis', 'holidays'],\n",
    "    ['longitude', 'latitude', 'current_dis', 'speeds', 'holidays'],\n",
    "]\n",
    "\n",
    "# 全部可选模型\n",
    "all_model_types = [\n",
    "    LSTMPredictor,\n",
    "    BiLSTMPredictor,\n",
    "    GRUPredictor\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集：验证集：测试集 == 6:2:2\n",
    "def split_dataset(df, features, window_size):\n",
    "    seq, label = createSequence(df, features, window_size)\n",
    "\n",
    "    # train\n",
    "    train_seq, test_seq = train_test_split(seq, test_size=0.4, random_state=seed)\n",
    "    train_label, test_label = train_test_split(label, test_size=0.4, random_state=seed)\n",
    "\n",
    "    # val & test\n",
    "    val_seq, test_seq = train_test_split(test_seq, test_size=0.5, random_state=seed)\n",
    "    val_label, test_label = train_test_split(test_label, test_size=0.5, random_state=seed)\n",
    "\n",
    "    return train_seq, train_label, val_seq, val_label, test_seq, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部分参数\n",
    "window_size = 15\n",
    "lr = 1e-2\n",
    "epoch_num = 200\n",
    "logging_steps = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试多种模型与特征\n",
    "best_model = None\n",
    "best_features = []\n",
    "min_rmse = 1e+5\n",
    "\n",
    "# 遍历特征\n",
    "for features in all_features:\n",
    "    train_seq, train_label, val_seq, val_label, test_seq, test_label = split_dataset(df, features, window_size)\n",
    "    # 遍历模型\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            model = LSTMPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        elif i == 1:\n",
    "            model = BiLSTMPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        else:\n",
    "            model = GRUPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        print(f'current features: {features}', flush=True)\n",
    "        print(f'current model_type: {type(model)}', flush=True)\n",
    "        \n",
    "        # 训练\n",
    "        if 'speeds' in features:\n",
    "            model, loss, rmse = trainModel(train_seq, train_label, val_seq, val_label, model,\n",
    "                                           lr, epoch_num * 2, logging_steps)\n",
    "        else:\n",
    "            model, loss, rmse = trainModel(train_seq, train_label, val_seq, val_label, model,\n",
    "                                           lr, epoch_num, logging_steps)\n",
    "        # 在（划分的）测试集上测试\n",
    "        predictions = []\n",
    "        test_set = TensorDataset(test_seq, test_label)\n",
    "        test_loader = DataLoader(test_set, batch_size=32, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                predictions.append(outputs)\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0)\n",
    "        test_rmse = calc_rmse(predictions, test_label)\n",
    "        print(f'test rmse: {test_rmse:.5f}')\n",
    "        print(f'=' * 80, end='\\n\\n', flush=True)\n",
    "\n",
    "        # 记录最好的模型\n",
    "        if test_rmse < min_rmse:\n",
    "            min_rmse = test_rmse\n",
    "            best_model = model\n",
    "            best_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: BiLSTMPredictor(\n",
      "  (lstm): LSTM(3, 108, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=216, out_features=3, bias=True)\n",
      ")\n",
      "best_features: ['longitude', 'latitude', 'current_dis']\n",
      "min_rmse: 0.328643\n"
     ]
    }
   ],
   "source": [
    "print(f'best model: {best_model}')\n",
    "print(f'best_features: {best_features}')\n",
    "print(f'min_rmse: {min_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 在真实测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>traj_id</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>current_dis</th>\n",
       "      <th>speeds</th>\n",
       "      <th>holidays</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355</td>\n",
       "      <td>2013-10-08T08:30:00Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.324127,39.897049]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.6075</td>\n",
       "      <td>0</td>\n",
       "      <td>116.324127</td>\n",
       "      <td>39.897049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356</td>\n",
       "      <td>2013-10-08T08:30:55Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.327652,39.897018]</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>21.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>116.327652</td>\n",
       "      <td>39.897018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357</td>\n",
       "      <td>2013-10-08T08:32:44Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.330978,39.897041]</td>\n",
       "      <td>0.584521</td>\n",
       "      <td>20.4825</td>\n",
       "      <td>0</td>\n",
       "      <td>116.330978</td>\n",
       "      <td>39.897041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358</td>\n",
       "      <td>2013-10-08T08:34:32Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.336624,39.897305]</td>\n",
       "      <td>1.067123</td>\n",
       "      <td>20.6575</td>\n",
       "      <td>0</td>\n",
       "      <td>116.336624</td>\n",
       "      <td>39.897305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359</td>\n",
       "      <td>2013-10-08T08:35:25Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.341118,39.897537]</td>\n",
       "      <td>1.451388</td>\n",
       "      <td>24.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>116.341118</td>\n",
       "      <td>39.897537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                  time  entity_id  traj_id             coordinates  \\\n",
       "0  355  2013-10-08T08:30:00Z        256       25  [116.324127,39.897049]   \n",
       "1  356  2013-10-08T08:30:55Z        256       25  [116.327652,39.897018]   \n",
       "2  357  2013-10-08T08:32:44Z        256       25  [116.330978,39.897041]   \n",
       "3  358  2013-10-08T08:34:32Z        256       25  [116.336624,39.897305]   \n",
       "4  359  2013-10-08T08:35:25Z        256       25  [116.341118,39.897537]   \n",
       "\n",
       "   current_dis   speeds  holidays   longitude   latitude  \n",
       "0     0.000000  21.6075         0  116.324127  39.897049  \n",
       "1     0.300751  21.1500         0  116.327652  39.897018  \n",
       "2     0.584521  20.4825         0  116.330978  39.897041  \n",
       "3     1.067123  20.6575         0  116.336624  39.897305  \n",
       "4     1.451388  24.0700         0  116.341118  39.897537  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real = pd.read_csv('data/jump_task.csv')\n",
    "\n",
    "# 填充空值（便于统一读取，且采用forward fill，不会影响minmax）\n",
    "df_real['coordinates'] = df_real['coordinates'].ffill()\n",
    "df_real['current_dis'] = df_real['current_dis'].ffill()\n",
    "\n",
    "df_real[['longitude', 'latitude']] = pd.DataFrame(\n",
    "    df_real['coordinates'].apply(lambda x: eval(x)).tolist(), index=df_real.index\n",
    ")\n",
    "df_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1959, 14, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分轨迹\n",
    "traj_index_list = df_real.groupby(['traj_id']).size()      # Series\n",
    "\n",
    "traj_list = []\n",
    "for index, length in traj_index_list.items():\n",
    "    traj_id = index\n",
    "    trajectory = df_real[(df_real['traj_id'] == traj_id)][best_features].values.tolist()\n",
    "    traj_list.append(trajectory[:14])\n",
    "\n",
    "traj_seq = torch.tensor(np.array(traj_list), dtype=torch.float32)\n",
    "traj_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1959, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "predictions = best_model(traj_seq)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入新文件\n",
    "df_pred = pd.read_csv('data/jump_task.csv')\n",
    "windows_size = 15\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    coordinates = f\"[{pred[0].item():.6f},{pred[1].item():.6f}]\"\n",
    "    current_dis = pred[2].item()\n",
    "    cur_line = (i + 1) * window_size - 1\n",
    "\n",
    "    df_pred.loc[cur_line, 'coordinates'] = coordinates\n",
    "    df_pred.loc[cur_line, 'current_dis'] = current_dis\n",
    "\n",
    "df_pred.to_csv('data/jump_task-pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们的实验中，Optuna 简洁、高效，故仅展示 Optuna 自动调优\n",
    "\n",
    "基于上面的实验结果，我们这里选取的模型特征组合是：**Bi-LSTM + holidays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q optuna\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv('data/traj.csv')\n",
    "\n",
    "# 1. 将时间time转为基于最早时间的偏移time_offset\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "base_time = df['time'].min()\n",
    "df['time_offset'] = (df['time'] - base_time).dt.total_seconds()\n",
    "\n",
    "# 2. 将coordinates列转换为经度和纬度两列\n",
    "df[['longitude', 'latitude']] = pd.DataFrame(df['coordinates'].apply(lambda x: eval(x)).tolist(), index=df.index)\n",
    "\n",
    "# 3. 将holidays转为float32\n",
    "df['holidays'] = df['holidays'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集 = 8:2\n",
    "features = ['longitude', 'latitude', 'current_dis', 'holidays']\n",
    "X, y = createSequence(df, features, window_size)\n",
    "X_train, X_val = train_test_split(X, test_size=0.2, random_state=seed)\n",
    "y_train, y_val = train_test_split(y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([163064, 14, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [32, 48, 64, 96, 108, 128])\n",
    "    lr = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 20, 400)\n",
    "\n",
    "    model = BiLSTMPredictor(X_train.shape[2], hidden_size, y_train.shape[1]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        preds.append(outputs)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        rmse = calc_rmse(preds, y_val)\n",
    "\n",
    "    # 以 rmse 作为目标值\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')   # 目标最小化\n",
    "study.optimize(objective, n_trials=400)\n",
    "\n",
    "# 打印最佳参数和目标值\n",
    "print('Best Parameters:', study.best_params)\n",
    "print('Best Objective Value:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [02:43<10:53,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.000146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [05:27<08:09,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, loss: 0.000948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [08:11<05:27,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, loss: 0.000337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [10:55<02:36,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, loss: 0.000203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [13:37<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, loss: 0.000248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 部分参数\n",
    "window_size = 15\n",
    "lr = 1e-2\n",
    "epoch_num = 200\n",
    "logging_steps = 40\n",
    "\n",
    "features = ['longitude', 'latitude', 'current_dis', 'holidays']\n",
    "X, y = createSequence(df, features, window_size)\n",
    "model = BiLSTMPredictor(X.shape[2], 108, y.shape[1]).to(device)\n",
    "\n",
    "train_set = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "# 初始化损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# 模型训练\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss.item()\n",
    "\n",
    "    # log\n",
    "    if epoch % logging_steps == (logging_steps - 1):\n",
    "        print(f\"Epoch {epoch + 1}, loss: {loss / len(train_loader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
